import streamlit as st
import asyncio
import re
from autogen import AssistantAgent, UserProxyAgent
from autogen import ConversableAgent
import pandas as pd
import plotly.express as px
import logging
import os
from dotenv import load_dotenv


# load_dotenv()  # è®€å– .env æ–‡ä»¶
# api_key = os.getenv("OPENAI_API_KEY")

api_key = st.secrets["api_keys"]["OPENAI_API_KEY"]

question = "é¢¨ç®é™¤äº†å¨›æ¨‚ï¼Œé‚„èƒ½ç”¨ä»€éº¼å…¶ä»–å‰µæ„ç”¨é€”ï¼Ÿ"

# è¨­å®š Streamlit é é¢
st.set_page_config(page_title="LLM & Human Discussion Framework", page_icon="ğŸ§‘", layout="wide")
st.title("LLM + Human Discussion Framework (LLM First)")

# å´é‚Šæ¬„ï¼šé…ç½®æœ¬åœ° API
with st.sidebar:
    st.header("æ¨¡å‹èˆ‡ API è¨­å®š")
    selected_model = st.selectbox("é¸æ“‡æ¨¡å‹", ["llama3-taiwan", "llama-3-taiwan-13.3b-instruct-i1", "gpt-4o-mini", "llama-3.2-1b-instruct", "gpt-4o"], index=0)
    base_url = None
    if "gpt" not in selected_model:
        base_url = st.text_input("API ç«¯é»", "http://127.0.0.1:1234/v1")
    rounds = st.slider("è¨­å®šè¨è«–è¼ªæ¬¡", min_value=1, max_value=99, value=10)
    temperature = st.slider("è¨­å®šæº«åº¦ (temperature)", min_value=0.0, max_value=2.0, value=1.0, step=0.1)

# åœæ­¢åŸ·è¡Œå¦‚æœ API ç«¯é»æœªè¨­ç½®
if not base_url and "gpt" not in selected_model:
    st.warning("è«‹è¼¸å…¥ API ç«¯é»ï¼", icon="âš ï¸")
    st.stop()

# LLM é…ç½®
llm_config = {
    "config_list": [
        {
            "model": selected_model,
            "api_key": None,
            "base_url": base_url,
            "temperature": temperature,
            "stream": True
        }
    ]
}

# Function to sanitize names
def sanitize_name(name):
    return re.sub(r'[^a-zA-Z0-9_-]', '_', name)

# å‰µå»ºè§’è‰²ä»£ç†
agents = {
    "Normal Assistant 1": ConversableAgent(
        name=sanitize_name("Normal Assistant 1"),
        llm_config=llm_config,
        system_message="ä½ æ˜¯ Normal Assistant 1ï¼Œä½ ç¾åœ¨è¦è·Ÿå…¶ä»–agentä¸€åŒé€²è¡Œè…¦åŠ›æ¿€ç›ªï¼Œ"
    ),
    "Normal Assistant 2": ConversableAgent(
        name=sanitize_name("Normal Assistant 2"),
        llm_config=llm_config,
        system_message="ä½ æ˜¯ Normal Assistant 2ã€‚ï¼Œä½ ç¾åœ¨è¦è·Ÿå…¶ä»–agentä¸€åŒé€²è¡Œè…¦åŠ›æ¿€ç›ªï¼Œ"
    ),
     "Convergence Judge": ConversableAgent(
        name=sanitize_name("Convergence Judge"),
        llm_config=llm_config,
        system_message="ä½ æ˜¯è…¦åŠ›æ¿€ç›ªè©•åˆ†å“¡ã€‚",
    ),
    "Assistant": ConversableAgent(
        name=sanitize_name("Assistant"),
        llm_config=llm_config,
        system_message="ä½ æ˜¯ Assistantã€‚",
    ),
    "User": UserProxyAgent(
        name=sanitize_name("User"),
        llm_config=llm_config,
        human_input_mode="NEVER",
    ),
}

# **å®šç¾©æ¯å€‹ Agent å°æ‡‰çš„ Avatarï¼ˆå¯ä½¿ç”¨æœ¬åœ°æˆ–ç¶²è·¯åœ–ç‰‡ï¼‰**
agent_avatars = {
    "Normal Assistant 1": "ğŸ¤–",  # ä½ çš„åŠ©ç† 1 åœ–ç‰‡
    "Normal Assistant 2": "ğŸ§ ",  # ä½ çš„åŠ©ç† 2 åœ–ç‰‡
    "Assistant": "ğŸ› ï¸",  # ä½ çš„Helper
}


# åˆå§‹åŒ–ç”¨æˆ¶ä»£ç†
user_proxy = UserProxyAgent(
    name=sanitize_name("User"),
    llm_config=llm_config,
    human_input_mode="NEVER",
)


# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
if "integrated_message" not in st.session_state:
    st.session_state.integrated_message = ""
if "discussion_started" not in st.session_state:
    st.session_state.discussion_started = False
if "round_num" not in st.session_state:
    st.session_state.round_num = 0
# Initialize or retrieve user input storage
if "user_inputs" not in st.session_state:
    st.session_state.user_inputs = {}
if "current_input" not in st.session_state:
    st.session_state.current_input = ""
if "show_input" not in st.session_state:
    st.session_state.show_input = True
if "this_round_combined_responses" not in st.session_state:
    st.session_state.this_round_combined_responses = {}
if "proxy_message_showed" not in st.session_state:
    st.session_state.proxy_message_showed = False

# åˆå§‹åŒ–æ¯è¼ªçš„å®Œæˆç‹€æ…‹
rounds = 99  # å‡è¨­ç¸½è¼ªæ•¸æ˜¯ 99ï¼Œå¯ä»¥æ ¹æ“šéœ€æ±‚èª¿æ•´
for i in range(rounds + 1):  # åŒ…æ‹¬ç¬¬ 0 è¼ª
    if f"round_{i}_completed" not in st.session_state:
        st.session_state[f"round_{i}_completed"] = False

# åˆå§‹åŒ–æ¯è¼ªçš„å®Œæˆç‹€æ…‹
rounds = 99  # å‡è¨­ç¸½è¼ªæ•¸æ˜¯ 99ï¼Œå¯ä»¥æ ¹æ“šéœ€æ±‚èª¿æ•´
for i in range(rounds + 1):  # åŒ…æ‹¬ç¬¬ 0 è¼ª
    if f"round_{i}_input_completed" not in st.session_state:
        st.session_state[f"round_{i}_input_completed"] = False


# åˆå§‹åŒ–ä»£ç†çš„å›è¦†ç‹€æ…‹
def initialize_agent_states(round_num, agents):
    if f"round_{round_num}_agent_states" not in st.session_state:
        st.session_state[f"round_{round_num}_agent_states"] = {
            agent_name: False for agent_name in agents.keys()
        }

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(agent_avatars.get(message["role"], message["role"])):
        st.markdown(message["content"])

# æ›´æ–°æŸä»£ç†çš„å›è¦†ç‹€æ…‹
def mark_agent_completed(round_num, agent_name):
    st.session_state[f"round_{round_num}_agent_states"][agent_name] = True


async def single_round_discussion(round_num, agents, user_proxy):
    initialize_agent_states(round_num, agents)
    
    # å¦‚æœè©²è¼ªå·²å®Œæˆï¼Œç›´æ¥è¿”å› True
    if st.session_state.get(f"round_{round_num}_completed", False):
        return True

    if round_num == 0:
        discussion_message = (
            f"é€™æ˜¯ç¬¬0è¼ªï¼Œ{question}"
        )
    else:
        # è¨­å®šä½¿ç”¨è€… Ideation Technique æ¨¡æ¿
        ideation_tech = "SCAMPER - Combine"

        user_input = "çµåˆ AI èªéŸ³åŠ©æ‰‹èˆ‡æ™‚é–“ç®¡ç†å·¥å…·"
        # è¨­å®šä½¿ç”¨è€… Ideation Technique è¨è«–æ¨¡æ¿
        discussion_message = (
            f"ğŸ”„ **ç¬¬ {round_num} è¼ªè¨è«–** ğŸ”„\n\n"
            f"ğŸ“Œ **è¨è«–ä¸»é¡Œï¼š** {question}\n\n"
            f"ğŸ¯ **ä½¿ç”¨è€…é¸æ“‡çš„å‰µæ„æ€è€ƒæŠ€è¡“ï¼š{ideation_tech} **\n"
            f"ğŸ’¡ **ä½¿ç”¨è€…è¼¸å…¥ï¼š**ã€Œ{st.session_state.user_inputs.get(round_num-1, "")}ã€\n\n"
            
            f"ğŸ“ **è«‹é‡å°ä¸Šè¼ªè¨è«–é€²è¡Œå»¶ä¼¸ï¼Œä¸¦åŸºæ–¼ {ideation_tech} æå‡ºæ›´å¤šå‰µæ–°ç™¼æƒ³ï¼**\n"
            f"ğŸ‘‰ ä½ å¯ä»¥é€²ä¸€æ­¥**ç´°åŒ–ç¾æœ‰å‰µæ„ã€å¢åŠ æ‡‰ç”¨å ´æ™¯ï¼Œæˆ–æŒ‘æˆ°ç¾æœ‰å‡è¨­**ã€‚\n\n"
            
            f"ğŸ“‘ **å›æ‡‰æ ¼å¼å»ºè­°ï¼š**\n"
            f"1ï¸âƒ£ **æ–°è§€é»æˆ–æ”¹é€²**ï¼ˆå¦‚ä½•é€²ä¸€æ­¥æå‡é€™å€‹å‰µæ„ï¼Ÿï¼‰\n"
            f"2ï¸âƒ£ **å¯èƒ½çš„æ‡‰ç”¨å ´æ™¯**ï¼ˆé€™å€‹æƒ³æ³•å¯ä»¥æ‡‰ç”¨åœ¨å“ªäº›æ–°çš„é ˜åŸŸï¼Ÿï¼‰\n"
            f"3ï¸âƒ£ **å¯èƒ½çš„æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆ**ï¼ˆæœ‰å“ªäº›æŠ€è¡“ã€å•†æ¥­æˆ–ä½¿ç”¨è€…æŒ‘æˆ°ï¼Ÿå¦‚ä½•å…‹æœï¼Ÿï¼‰\n\n"

            f"ğŸ’¡ **è«‹æ ¹æ“šä½ çš„å‰µæ„æ€è€ƒæŠ€è¡“é€²è¡Œå›æ‡‰ï¼** ğŸš€"
        )


    
    this_round_input = st.session_state.user_inputs.get(round_num, "")


    for agent_name, agent in agents.items():
        if st.session_state[f"round_{round_num}_completed"]:
            break

        # st.write("é–‹é ­")
        # st.write(st.session_state.messages)
        if agent_name in ["Convergence Judge"]:
            continue


        # æœ€å¾Œä¸€å€‹ agent å¾Œç­‰å¾…user_inputå¾Œå†é€²è¡Œä¸‹ä¸€è¼ª
        if agent_name == "User":
            # è™•ç†ç”¨æˆ¶è¼¸å…¥ï¼Œåªé‡å°ç•¶å‰è¼ªæ¬¡
            if this_round_input != "":
                # Display user message in chat message container
                # st.chat_message("user").markdown(this_round_input)
                # Add user message to chat history
                st.session_state.messages.append({"role": "user", "content": this_round_input})
                st.session_state[f"round_{round_num}_input_completed"] = True
                st.session_state.this_round_combined_responses[agent_name] = this_round_input
                st.session_state.user_inputs[round_num] = this_round_input
                st.write(f"User è¼¸å…¥å®Œæˆï¼š{this_round_input}")
                with st.chat_message("user"):
                    st.markdown(this_round_input)
                st.session_state.proxy_message_showed = False
            else:
                # ç­‰å¾…è¼¸å…¥
                return False
        elif agent_name == "Assistant":
                if st.session_state[f"round_{round_num}_agent_states"][agent_name]:
                    # st.write(f"{agent_name} å·²å®Œæˆ")
                    continue

                this_round_response = {}
                for agent_name_each, response in st.session_state.this_round_combined_responses.items():
                    if agent_name_each in ["User", "Assistant"]:
                        continue
                    this_round_response[agent_name_each] = response

                category_prompt = (
                    f"ä½ æ˜¯ä¸€å€‹æ“…é•·è³‡è¨Šçµ±æ•´çš„ AIï¼Œè² è²¬æ•´ç†ä¾†è‡ªä¸åŒ AI åŠ©æ‰‹çš„å›æ‡‰ï¼Œä¸¦ç¢ºä¿åˆ†é¡æ¸…æ™°ã€æœ‰æ¢ç†ã€‚"
                    f"\n\nğŸ’¡ **é€™äº› AI ä¾†è‡ªä¸åŒé ˜åŸŸï¼ŒåŒ…æ‹¬ï¼š**"
                    f"\nğŸ”¹ Normal Assistant 1ï¼ˆ{agents['Normal Assistant 1'].system_message}ï¼‰"
                    f"\nğŸ”¹ Normal Assistant 2ï¼ˆ{agents['Normal Assistant 2'].system_message}ï¼‰"
                    # f"\nğŸ”¹ Convergence Judgeï¼ˆ{agents['Convergence Judge'].system_message}ï¼‰"
                    f"\n\nğŸ“Œ **é€™ä¸€è¼ªçš„è¨è«–ç´€éŒ„ï¼š**"
                    f"\n{this_round_response}"
                    f"\n\n**è«‹æŒ‰ç…§ä»¥ä¸‹è¦æ±‚çµ±æ•´è³‡è¨Šï¼š**"
                    f"\n1ï¸âƒ£ **æ¨™è¨˜ AI ä¾†æº**ï¼šè«‹åœ¨æ¯å€‹è§€é»å‰æ¨™ç¤ºè©² AI çš„åç¨±ï¼Œä¾‹å¦‚ã€Normal Assistant 1ã€‘ã€ã€Normal Assistant 2ã€‘"
                    f"\n2ï¸âƒ£ **ä¸»å‹•åˆ¤æ–·åˆ†é¡**ï¼šæ ¹æ“šå…§å®¹è‡ªå‹•é¸æ“‡æœ€åˆé©çš„åˆ†é¡ï¼Œä¾‹å¦‚ã€ŒæŠ€è¡“å‰µæ–°ã€ã€ã€Œå¸‚å ´è¶¨å‹¢ã€ã€ã€ŒæŒ‘æˆ°èˆ‡é¢¨éšªã€ã€ã€Œæœªä¾†æ‡‰ç”¨ã€ç­‰"
                    f"\n3ï¸âƒ£ **é¿å…é‡è¤‡**ï¼šè‹¥å¤šå€‹ AI æå‡ºç›¸ä¼¼è§€é»ï¼Œè«‹åˆä½µè™•ç†ï¼Œä¸¦æ¨™ç¤ºä¸åŒ AI çš„è£œå……æ„è¦‹"
                    f"\n4ï¸âƒ£ **ç¸½çµä¸»è¦ç™¼ç¾**ï¼šåœ¨æœ€å¾Œæä¾› 2-3 å¥è©±çš„æ‘˜è¦ï¼Œæ­¸ç´è¨è«–çš„æ ¸å¿ƒé‡é»"
                    f"\n\nğŸ“Œ **æ ¼å¼ç¯„ä¾‹ï¼š**"
                    f"\nã€æŠ€è¡“å‰µæ–°ã€‘"
                    f"\n- ã€Normal Assistant 1ã€‘æå‡ºã€é¢¨åŠ›ç™¼é›»é¢¨ç®ã€ï¼Œå¼·èª¿å…¶èƒ½æºè½‰æ›æ•ˆç‡"
                    f"\n- ã€Normal Assistant 2ã€‘è£œå……è©²æŠ€è¡“å¯æ­é… AI è‡ªé©æ‡‰é£›è¡Œï¼Œæé«˜ç©©å®šæ€§"
                    f"\n- ã€Convergence Judgeã€‘æé†’è©²æŠ€è¡“ä»éœ€é€²ä¸€æ­¥æ¸¬è©¦ç©©å®šæ€§"
                    f"\n\nã€å¸‚å ´è¶¨å‹¢ã€‘"
                    f"\n- ã€Normal Assistant 1ã€‘èªç‚º NFT é¢¨ç®å…·å¸‚å ´æ½›åŠ›ï¼Œå› ç‚ºæ”¶è—å“å¸‚å ´æ­£åœ¨æˆé•·"
                    f"\n- ã€Convergence Judgeã€‘è³ªç–‘å…¶é•·æœŸåƒ¹å€¼ï¼Œèªç‚º NFT å¸‚å ´çš„ä¸ç¢ºå®šæ€§è¼ƒé«˜"
                    f"\n\nğŸ“Œ **ç¸½çµ**"
                    f"\næœ¬è¼ªè¨è«–é¡¯ç¤ºï¼Œé¢¨åŠ›ç™¼é›»é¢¨ç®åœ¨æŠ€è¡“ä¸Šæœ‰æ½›åŠ›ï¼Œä½†ä»éœ€è§£æ±ºç©©å®šæ€§å•é¡Œã€‚NFT é¢¨ç®åœ¨å¸‚å ´æ½›åŠ›ä¸Šå­˜åœ¨çˆ­è­°ï¼Œå€¼å¾—é€²ä¸€æ­¥æ¢è¨ã€‚"
                    f"\n\nğŸ‘‰ **è«‹å‘Šè¨´æˆ‘ä½ æƒ³é€²ä¸€æ­¥æ¢è¨å“ªå€‹éƒ¨åˆ†ï¼Ÿæˆ‘å¯ä»¥æä¾›æ›´å¤šç´°ç¯€ï¼**"
                )

                response = await agent.a_initiate_chat(user_proxy, message=category_prompt, max_turns=1)
                response = response.chat_history[-1]["content"].strip()
                st.session_state.this_round_combined_responses[agent_name] = response
                # Display assistant response in chat message container
                with st.chat_message(agent_avatars.get(agent_name, agent_name)):
                    st.markdown(response)
                # Add assistant response to chat history
                st.session_state.messages.append({"role": agent_name, "content": response})
                
                mark_agent_completed(round_num, agent_name)

        else:
            if not st.session_state.proxy_message_showed:
                with st.chat_message(agent_avatars.get("assistant", "assistant")):
                    st.markdown(discussion_message)
                st.session_state.proxy_message_showed = True
                
            if st.session_state[f"round_{round_num}_agent_states"][agent_name]:
                continue
            st.write(f"{agent_name} è™•ç†ä¸­...")

            st.session_state.messages.append({"role": "assistant", "content": discussion_message})
            response = await agent.a_initiate_chat(user_proxy, message=discussion_message, max_turns=1)
            response = response.chat_history[-1]["content"].strip()
            st.session_state.this_round_combined_responses[agent_name] = response

            # # å°‡ AI å›æ‡‰é¡¯ç¤ºç‚ºæŠ˜ç–Šå¼
            # with st.expander(f"{agent_name} çš„å›æ‡‰ï¼ˆé»æ“Šå±•é–‹ï¼‰", expanded=False):
            #     st.markdown(response)

            # Display assistant response in chat message container
            with st.chat_message(agent_avatars.get(agent_name, agent_name)):
                # è®“å…§å®¹æŠ˜ç–Šï¼Œä½†ä»ä¿ç•™ chat_message æ¨£å¼
                with st.expander(f"æŸ¥çœ‹ {agent_name} çš„è©³ç´°å›æ‡‰ï¼ˆé»æ“Šå±•é–‹ï¼‰", expanded=False):
                    st.markdown(response)

            # Add assistant response to chat history
            st.session_state.messages.append({"role": agent_name, "content": response})
            mark_agent_completed(round_num, agent_name)


    
    return True

# åˆå§‹åŒ– refresh_flag
if "refresh_flag" not in st.session_state:
    st.session_state.refresh_flag = False


# åœ¨è¼¸å…¥æ¡†æ¶ˆå¤±å¾Œé¡¯ç¤ºæç¤ºï¼Œç„¶å¾Œå†é¡¯ç¤ºä¸‹ä¸€è¼ªè¼¸å…¥æ¡†
if not st.session_state.show_input:
    st.write(f"å·²å®Œæˆç¬¬ {st.session_state.round_num - 1} è¼ªçš„è¼¸å…¥ï¼")
    st.session_state.show_input = True


if not st.session_state.discussion_started:
    if st.button("é–‹å§‹ LLM è¨è«–"):
        st.session_state.discussion_started = True
        st.session_state.round_num = 0
        st.session_state.integrated_message = f"é€™æ˜¯ç¬¬ 0 è¼ªè¨è«–ï¼Œ{question}ã€‚"

if st.session_state.discussion_started and st.session_state.round_num <= rounds:
    
    round_num = st.session_state.round_num
    # åŸ·è¡Œå–®è¼ªè¨è«–
    completed = asyncio.run(single_round_discussion(
        st.session_state.round_num, agents, user_proxy
    ))


    if not st.session_state[f"round_{round_num}_input_completed"]:
        
        current_input = st.chat_input(f"è«‹è¼¸å…¥ç¬¬ {st.session_state.round_num} è¼ªçš„æƒ³æ³•ï¼š")
        
        if current_input:
            # ä¿å­˜è¾“å…¥å¹¶é‡ç½®çŠ¶æ€
            st.session_state.user_inputs[st.session_state.round_num] = current_input
            with st.chat_message("user"):
                st.markdown(current_input)

        completed = asyncio.run(single_round_discussion(
            st.session_state.round_num, agents, user_proxy
        ))

    if completed:
        # å¦‚æœè©²è¼ªå®Œæˆï¼Œé€²å…¥ä¸‹ä¸€è¼ª
        # st.write(f"å·²å®Œæˆç¬¬ {st.session_state.round_num} è¼ªï¼Œé€²å…¥ç¬¬ {st.session_state.round_num + 1} è¼ª")
        st.session_state.round_num += 1
        # time.sleep(1)
        st.rerun()
