import streamlit as st
import asyncio
import re
from autogen import AssistantAgent, UserProxyAgent
from autogen import ConversableAgent
import pandas as pd
import plotly.express as px
import logging

question = "é¢¨ç®é™¤äº†å¨›æ¨‚ï¼Œé‚„èƒ½ç”¨ä»€éº¼å…¶ä»–å‰µæ„ç”¨é€”ï¼Ÿ"

# è¨­å®š Streamlit é é¢
st.set_page_config(page_title="LLM & Human Discussion Framework", page_icon="ğŸ§‘", layout="wide")
st.title("LLM + Human Discussion Framework (Human First)")

# å´é‚Šæ¬„ï¼šé…ç½®æœ¬åœ° API
with st.sidebar:
    st.header("æ¨¡å‹èˆ‡ API è¨­å®š")
    selected_model = st.selectbox("é¸æ“‡æ¨¡å‹", ["llama3-taiwan", "llama-3-taiwan-13.3b-instruct-i1", "gpt-4o-mini", "llama-3.2-1b-instruct", "gpt-4o"], index=0)
    base_url = None
    if "gpt" not in selected_model:
        base_url = st.text_input("API ç«¯é»", "http://127.0.0.1:1234/v1")
    rounds = st.slider("è¨­å®šè¨è«–è¼ªæ¬¡", min_value=1, max_value=99, value=10)
    temperature = st.slider("è¨­å®šæº«åº¦ (temperature)", min_value=0.0, max_value=2.0, value=1.0, step=0.1)

# åœæ­¢åŸ·è¡Œå¦‚æœ API ç«¯é»æœªè¨­ç½®
if not base_url and "gpt" not in selected_model:
    st.warning("è«‹è¼¸å…¥ API ç«¯é»ï¼", icon="âš ï¸")
    st.stop()

# LLM é…ç½®
llm_config = {
    "config_list": [
        {
            "model": selected_model,
            "api_key": None,
            "base_url": base_url,
            "temperature": temperature,
            "stream": True
        }
    ]
}

# Function to sanitize names
def sanitize_name(name):
    return re.sub(r'[^a-zA-Z0-9_-]', '_', name)

# å‰µå»ºè§’è‰²ä»£ç†
agents = {
        "Normal Assistant 1": ConversableAgent(
        name=sanitize_name("Normal Assistant 1"),
        llm_config=llm_config,
        system_message="ä½ æ˜¯ Normal Assistant 1ï¼Œä½ ç¾åœ¨è¦è·Ÿå…¶ä»–agentä¸€åŒé€²è¡Œè…¦åŠ›æ¿€ç›ªï¼Œ"
        "åœ¨è¨è«–æ™‚è€ƒæ…®ä»¥ä¸‹æŒ‡æ¨™ï¼Œç‚ºå‰µæ„è©•ä¼°æ¨™æº–ï¼Œè¶Šé«˜è¶Šå¥½ï¼š\n"
        "- **Originality**: è¦æƒ³å‡ºæ–°å¥‡ã€æœ‰å‰µæ„çš„å›ç­”ï¼Œæ—¢ä¸æ˜¯è€å¥—ä¹Ÿä¸æ˜¯å¥‡æ€ªï¼Œè€Œæ˜¯è·Ÿå•é¡Œç›¸é—œçš„ã€‚\n"
        "- **Elaboration**: å›ç­”çš„æ™‚å€™æä¾›çš„ç´°ç¯€è¶Šå¤šè¶Šå¥½ã€‚\n"
        "- **Fluency**: å›ç­”ä¸­èƒ½çµ¦å‡ºç›¸é—œæ–¼é¡Œç›®çš„å…§å®¹è¶Šå¤šè¶Šå¥½ã€‚\n"
        "- **Flexibility**: å›ç­”ä¸­åŒ…å«çš„ç¨®é¡æˆ–æ–¹å‘è¶Šå¤šè¶Šå¥½ã€‚\n\nã€‚",
    ),
    "Normal Assistant 2": ConversableAgent(
        name=sanitize_name("Normal Assistant 2"),
        llm_config=llm_config,
        system_message="ä½ æ˜¯ Normal Assistant 2ã€‚ï¼Œä½ ç¾åœ¨è¦è·Ÿå…¶ä»–agentä¸€åŒé€²è¡Œè…¦åŠ›æ¿€ç›ªï¼Œ"
        "åœ¨è¨è«–æ™‚è€ƒæ…®ä»¥ä¸‹æŒ‡æ¨™ï¼Œç‚ºå‰µæ„è©•ä¼°æ¨™æº–ï¼Œè¶Šé«˜è¶Šå¥½ï¼š\n"
        "- **Originality**: è¦æƒ³å‡ºæ–°å¥‡ã€æœ‰å‰µæ„çš„å›ç­”ï¼Œæ—¢ä¸æ˜¯è€å¥—ä¹Ÿä¸æ˜¯å¥‡æ€ªï¼Œè€Œæ˜¯è·Ÿå•é¡Œç›¸é—œçš„ã€‚\n"
        "- **Elaboration**: å›ç­”çš„æ™‚å€™æä¾›çš„ç´°ç¯€è¶Šå¤šè¶Šå¥½ã€‚\n"
        "- **Fluency**: å›ç­”ä¸­èƒ½çµ¦å‡ºç›¸é—œæ–¼é¡Œç›®çš„å…§å®¹è¶Šå¤šè¶Šå¥½ã€‚\n"
        "- **Flexibility**: å›ç­”ä¸­åŒ…å«çš„ç¨®é¡æˆ–æ–¹å‘è¶Šå¤šè¶Šå¥½ã€‚\n\nã€‚",
    ),
     "Convergence Judge": ConversableAgent(
        name=sanitize_name("Convergence Judge"),
        llm_config=llm_config,
        system_message="ä½ æ˜¯è…¦åŠ›æ¿€ç›ªè©•åˆ†å“¡ã€‚",
    ),
    "Assistant": ConversableAgent(
        name=sanitize_name("Assistant"),
        llm_config=llm_config,
        system_message="ä½ æ˜¯ Assistantã€‚",
    ),
}

# åˆå§‹åŒ–ç”¨æˆ¶ä»£ç†
user_proxy = UserProxyAgent(
    name=sanitize_name("User"),
    llm_config=llm_config,
    human_input_mode="NEVER",
)


# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
if "integrated_message" not in st.session_state:
    st.session_state.integrated_message = ""
if "discussion_started" not in st.session_state:
    st.session_state.discussion_started = False
if "round_num" not in st.session_state:
    st.session_state.round_num = 0
# Initialize or retrieve user input storage
if "user_inputs" not in st.session_state:
    st.session_state.user_inputs = {}
if "current_input" not in st.session_state:
    st.session_state.current_input = ""
if "show_input" not in st.session_state:
    st.session_state.show_input = True
if "this_round_combined_responses" not in st.session_state:
    st.session_state.this_round_combined_responses = {}
if "passed_ideas" not in st.session_state:
    st.session_state.passed_ideas = []
if "full_scores" not in st.session_state:
    st.session_state.full_scores = []


# åˆå§‹åŒ–æ¯è¼ªçš„å®Œæˆç‹€æ…‹
rounds = 99  # å‡è¨­ç¸½è¼ªæ•¸æ˜¯ 99ï¼Œå¯ä»¥æ ¹æ“šéœ€æ±‚èª¿æ•´
for i in range(rounds + 1):  # åŒ…æ‹¬ç¬¬ 0 è¼ª
    if f"round_{i}_completed" not in st.session_state:
        st.session_state[f"round_{i}_completed"] = False

# åˆå§‹åŒ–æ¯è¼ªçš„å®Œæˆç‹€æ…‹
rounds = 99  # å‡è¨­ç¸½è¼ªæ•¸æ˜¯ 99ï¼Œå¯ä»¥æ ¹æ“šéœ€æ±‚èª¿æ•´
for i in range(rounds + 1):  # åŒ…æ‹¬ç¬¬ 0 è¼ª
    if f"round_{i}_input_completed" not in st.session_state:
        st.session_state[f"round_{i}_input_completed"] = False
async def check_novelty_and_feasibility(round_num, integrated_history_with_categories, current_round_responses, if_zero_round=False):

    current_round_message = (
        "ä»¥ä¸‹æ˜¯æœ¬è¼ªå°è©±ï¼Œè«‹å¹«æˆ‘ç¸½çµå‰µæ„éƒ¨åˆ†ï¼Œå¿½ç•¥å•å€™èªèˆ‡ç„¡é—œå…§å®¹ï¼Œè«‹å¿½ç•¥æ‰€æœ‰ Markdown æ ¼å¼åŒ–ç¬¦è™Ÿï¼ˆå¦‚ `#`, `*`, `**` ç­‰ï¼‰ï¼Œåƒ…æå–è¨è«–ä¸­çš„æœ‰ç”¨å…§å®¹ã€‚"
        f"{current_round_responses}"
        "è«‹è¼¸å‡ºç°¡æ½”ç‰ˆï¼Œåƒ…ä¿ç•™å‰µæ„ã€‚"
    )

    print("XXXXXXXXXXXXXXXXXXXXXX")
    print(current_round_message)
    print("XXXXXXXXXXXXXXXXXXXXXX")

    current_round_responses = await agents["Assistant"].a_initiate_chat(user_proxy, message=current_round_message, max_turns=1)
    current_round_responses = current_round_responses.chat_history[-1]["content"].strip()

    print("OOOOOOOOOOOOOOOO")
    print(current_round_responses)
    print("OOOOOOOOOOOOOOOO")

    if if_zero_round:
        integrated_history_message = ""
    else:
        integrated_history_message = (
            "ä»¥ä¸‹æ˜¯æ•´åˆæ­·å²è¨è«–å…§å®¹ï¼Œè«‹å¹«æˆ‘ç¸½çµå‰µæ„éƒ¨åˆ†ï¼Œå¿½ç•¥å•å€™èªèˆ‡ç„¡é—œå…§å®¹ï¼Œè«‹å¿½ç•¥æ‰€æœ‰ Markdown æ ¼å¼åŒ–ç¬¦è™Ÿï¼ˆå¦‚ `#`, `*`, `**` ç­‰ï¼‰ï¼Œåƒ…æå–è¨è«–ä¸­çš„æœ‰ç”¨å…§å®¹ã€‚"
            f"{integrated_history_with_categories}"
            "è«‹è¼¸å‡ºç°¡æ½”ç‰ˆï¼Œåƒ…ä¿ç•™å‰µæ„ã€‚"
        )
        integrated_history_message = await agents["Assistant"].a_initiate_chat(user_proxy, message=integrated_history_message, max_turns=1)
        integrated_history_message = integrated_history_message.chat_history[-1]["content"].strip()

    st.markdown("---")
    categorize_message = (
        "è«‹å°‡è¨è«–å…§å®¹é€²è¡Œæ•´åˆåˆ†é¡ï¼Œä¸¦è©•ä¼°å‰µæ„çš„è³ªé‡ï¼š"
        "## æŒ‡æ¨™å®šç¾©ï¼š\n"
        "- **Originality**: è¦æƒ³å‡ºæ–°å¥‡ã€æœ‰å‰µæ„çš„å›ç­”ï¼Œæ—¢ä¸æ˜¯è€å¥—ä¹Ÿä¸æ˜¯å¥‡æ€ªï¼Œè€Œæ˜¯è·Ÿå•é¡Œç›¸é—œçš„ã€‚\n"
        "- **Elaboration**: å›ç­”çš„æ™‚å€™æä¾›çš„ç´°ç¯€è¶Šå¤šè¶Šå¥½ã€‚\n"
        "- **Fluency**: å›ç­”ä¸­èƒ½çµ¦å‡ºç›¸é—œæ–¼é¡Œç›®çš„å…§å®¹è¶Šå¤šè¶Šå¥½ã€‚\n"
        "- **Flexibility**: å›ç­”ä¸­åŒ…å«çš„ç¨®é¡æˆ–æ–¹å‘è¶Šå¤šè¶Šå¥½ã€‚\n\n"
        "## å•é¡Œï¼š\n"
        f"{question}\n\n"

        "ç›®æ¨™ï¼š"
        "1. å°æœ¬è¼ªå›æ‡‰ä¸­çš„æ¯å€‹å‰µæ„ï¼Œæ ¹æ“šå››å€‹æŒ‡æ¨™é€²è¡Œé€é …è©•ä¼°ä¸¦çµ¦å‡ºåˆ†æ•¸ï¼ˆ0-100ï¼‰ã€‚\n"
        "2. æä¾›æœ¬è¼ªå›æ‡‰çš„å¹³å‡åˆ†æ•¸ï¼ˆç²¾ç¢ºåˆ°å°æ•¸é»ï¼‰ã€‚\n"
        "3. è«‹åŸºæ–¼æ­·å²å›æ‡‰åˆ†é¡ï¼Œå°‡æ–°ä¸€è¼ªçš„å‰µæ„æŒ‰ç…§åŠŸèƒ½é€²è¡Œåˆ†é¡ã€‚\n"
        "4. ä¸Šä¸€è¼ªçš„åˆ†é¡ä¸åšæ›´å‹•ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´çš„æ­·å²è¨˜éŒ„ã€‚\n"
        "5. æ–°ä¸€è¼ªçš„å‰µæ„ç›´æ¥æŒ‰åŠŸèƒ½åˆ†é¡ï¼Œä¿æŒåŸå§‹æè¿°ï¼Œä¸å°å…§å®¹é€²è¡Œç°¡åŒ–æˆ–æ•´ç†ã€‚\n"
        "6. å¦‚æœ‰å¿…è¦ï¼Œå¯æ–°å¢åˆ†é¡ï¼Œä¸¦èªªæ˜æ–°å¢åˆ†é¡çš„åŸå› ã€‚\n"

        f"## ç¬¬{round_num-1}è¼ªæ­·å²åˆ†é¡ï¼š\n"
        f"{integrated_history_message}\n\n"
        f"## ç¬¬{round_num}è¼ªå›æ‡‰ï¼š\n"
        f"{current_round_responses}\n\n"


        f"\n\nå›æ‡‰æ ¼å¼ï¼š(è«‹åš´æ ¼éµå®ˆå›å‚³æ–¹å¼)\n"
        f"\n## ç¬¬{round_num}è¼ªå›æ‡‰å‰µæ„è©•åˆ†ï¼š(è«‹åš´æ ¼éµå®ˆå›å‚³æ–¹å¼)\n"
        "- {å‰µæ„ 1é …ç›®}_{å‰µæ„ 1çš„å…·é«”åŸ·è¡Œæ–¹å¼}(ä¾‹å­: å‰å­_ä½¿ç”¨å‰å­æ‹¿ä¾†åšé¤å…·): Originality {åˆ†æ•¸}/100, Elaboration {åˆ†æ•¸}/100, Fluency {åˆ†æ•¸}/100, Flexibility {åˆ†æ•¸}/100\n"
        "- {å‰µæ„ 2é …ç›®}_{å‰µæ„ 2çš„å…·é«”åŸ·è¡ŒåŠŸèƒ½}(ä¾‹å­: å‰å­_ä½¿ç”¨å‰å­æ‹¿ä¾†åšé¤å…·): Originality {åˆ†æ•¸}/100, Elaboration {åˆ†æ•¸}/100, Fluency {åˆ†æ•¸}/100, Flexibility {åˆ†æ•¸}/100\n"
        f"\n## ç¬¬{round_num}è¼ªå›æ‡‰å¹³å‡åˆ†æ•¸ï¼š\n"
        "Originalityï¼š{æœ¬è¼ªå›æ‡‰Originalityå¹³å‡åˆ†æ•¸(å°æ•¸é»)}\n"
        "Elaborationï¼š{æœ¬è¼ªå›æ‡‰Elaborationå¹³å‡åˆ†æ•¸(å°æ•¸é»)}\n"
        "Fluencyï¼š{æœ¬è¼ªå›æ‡‰Fluencyå¹³å‡åˆ†æ•¸(å°æ•¸é»)}\n"
        "Flexibilityï¼š{æœ¬è¼ªå›æ‡‰Flexibilityå¹³å‡åˆ†æ•¸(å°æ•¸é»)}\n"
        f"\n## ç¬¬{round_num-1}è¼ªçš„å›æ‡‰ï¼š\n"
        f"{integrated_history_message}\n"
        f"\n## ç¬¬{round_num-1}è¼ªæ­·å²å›æ‡‰çš„åˆ†é¡ï¼š\n"
        f"- åˆ†é¡ 1: \n"
        f"  - åŸå§‹å‰µæ„: [å‰µæ„å…§å®¹ 1 (ä¾†è‡ªç¬¬ X è¼ª), å‰µæ„å…§å®¹ 2 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"  - æ–°å¢å‰µæ„: [æ–°å¢å‰µæ„å…§å®¹ 1 (ä¾†è‡ªç¬¬ X è¼ª), æ–°å¢å‰µæ„å…§å®¹ 2 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"- åˆ†é¡ 2: \n"
        f"  - åŸå§‹å‰µæ„: [å‰µæ„å…§å®¹ 3 (ä¾†è‡ªç¬¬ X è¼ª), å‰µæ„å…§å®¹ 4 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"  - æ–°å¢å‰µæ„: [æ–°å¢å‰µæ„å…§å®¹ 3 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"- åˆ†é¡ 3: \n"
        f"  - åŸå§‹å‰µæ„: [å‰µæ„å…§å®¹ 5 (ä¾†è‡ªç¬¬ X è¼ª), å‰µæ„å…§å®¹ 6 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"  - æ–°å¢å‰µæ„: [æ–°å¢å‰µæ„å…§å®¹ 4 (ä¾†è‡ªç¬¬ X è¼ª), æ–°å¢å‰µæ„å…§å®¹ 5 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"\n## ç¬¬{round_num}è¼ªçš„å›æ‡‰ï¼š\n"
        f"{current_round_responses}\n"
        f"\n## ç¬¬{round_num}è¼ªæ•´åˆå¾Œçš„åˆ†é¡èªªæ˜ï¼š\n"
        f"- åˆ†é¡ 1: \n"
        f"  - åŸå§‹å‰µæ„: [å‰µæ„å…§å®¹ 1 (ä¾†è‡ªç¬¬ X è¼ª), å‰µæ„å…§å®¹ 2 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"  - æ–°å¢å‰µæ„: [æ–°å¢å‰µæ„å…§å®¹ 1 (ä¾†è‡ªç¬¬ X è¼ª), æ–°å¢å‰µæ„å…§å®¹ 2 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"- åˆ†é¡ 2: \n"
        f"  - åŸå§‹å‰µæ„: [å‰µæ„å…§å®¹ 3 (ä¾†è‡ªç¬¬ X è¼ª), å‰µæ„å…§å®¹ 4 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"  - æ–°å¢å‰µæ„: [æ–°å¢å‰µæ„å…§å®¹ 3 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"- åˆ†é¡ 3: \n"
        f"  - åŸå§‹å‰µæ„: [å‰µæ„å…§å®¹ 5 (ä¾†è‡ªç¬¬ X è¼ª), å‰µæ„å…§å®¹ 6 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
        f"  - æ–°å¢å‰µæ„: [æ–°å¢å‰µæ„å…§å®¹ 4 (ä¾†è‡ªç¬¬ X è¼ª), æ–°å¢å‰µæ„å…§å®¹ 5 (ä¾†è‡ªç¬¬ X è¼ª)]ï¼ˆåŸå› ï¼šè«‹å…·é«”æè¿°åŸå› ï¼‰\n"
    )
    # st.write(categorize_message)
    st.markdown("---")



    # ä»£ç†é€²è¡Œåˆ†é¡
    response = await agents["Convergence Judge"].a_initiate_chat(user_proxy, message=categorize_message, max_turns=1)

    # å¾ chat_history æå–æœ€å¾Œä¸€æ¢è¨Šæ¯ï¼ˆä»£ç†çš„å›æ‡‰ï¼‰
    final_message = response.chat_history[-1]["content"].strip()

    st.write("### å‡ºä¾†çš„æ–°æŒ‡æ¨™")
    st.write(final_message)

    st.markdown("---")
    # æ­£å‰‡åŒ¹é…æ‰€æœ‰å›æ‡‰å¹³å‡åˆ†æ•¸æ®µè½
    pattern = r"## ç¬¬(\d+)è¼ªå›æ‡‰å¹³å‡åˆ†æ•¸ï¼š\s*([\s\S]*?)(?=##|$)"

    # è·å–æ‰€æœ‰åŒ¹é…
    matches = re.finditer(pattern, final_message, re.DOTALL)
    matches_list = list(matches)

    # è·å–ç¬¬ä¸€ä¸ªåŒ¹é…æ®µè½
    if matches_list:
        matches_text = matches_list[0].group(2)  # è·å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„å†…å®¹éƒ¨åˆ†
    else:
        raise ValueError("æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…æ®µè½")


 # æ­£å‰‡è¡¨é”å¼æå–æŒ‡æ¨™åˆ†æ•¸
    match = re.search(
        r"Originality[:ï¼š]\s*([\d.]+)|"
        r"Elaboration[:ï¼š]\s*([\d.]+)|"
        r"Fluency[:ï¼š]\s*([\d.]+)|"
        r"Flexibility[:ï¼š]\s*([\d.]+)",
        matches_text,
        re.MULTILINE
    )

    # å¦‚æœåŒ¹é…åˆ°äº†æŒ‡æ¨™åˆ†æ•¸ï¼Œé€ä¸€æå–
    if match:
        originality_match = re.search(r"Originality[:ï¼š]\s*([\d.]+)", matches_text)
        if originality_match:
            originality_score = float(originality_match.group(1))

        elaboration_match = re.search(r"Elaboration[:ï¼š]\s*([\d.]+)", matches_text)
        if elaboration_match:
            elaboration_score = float(elaboration_match.group(1))

        fluency_match = re.search(r"Fluency[:ï¼š]\s*([\d.]+)", matches_text)
        if fluency_match:
            fluency_score = float(fluency_match.group(1))

        flexibility_match = re.search(r"Flexibility[:ï¼š]\s*([\d.]+)", matches_text)
        if flexibility_match:
            flexibility_score = float(flexibility_match.group(1))


    # åŒ¹é…æ¯å€‹å‰µæ„çš„å‰µæ„åˆ†æ•¸
    # æ­£å‰‡è¡¨é”å¼ï¼šåŒ¹é…æ¯ä¸€è¡Œå‰µæ„åŠå…¶å››å€‹æŒ‡æ¨™
    pattern = r"-\s*(.*?)\s*(?:\n)?(?:-)?\s*Originality\s*[ï¼š:]?\s*(\d+)(?:/100)?,?\s*Elaboration\s*[ï¼š:]?\s*(\d+)(?:/100)?,?\s*Fluency\s*[ï¼š:]?\s*(\d+)(?:/100)?,?\s*Flexibility\s*[ï¼š:]?\s*(\d+)(?:/100)?"




    # æŒ‡å®šç¯©é¸æ¢ä»¶
    originality_threshold = 80
    flexibility_threshold = 80

    # åˆå§‹åŒ–ä¸€å€‹åˆ—è¡¨ä¾†å­˜å„²ç¬¦åˆæ¢ä»¶çš„å‰µæ„
    ideas = []

    # ä½¿ç”¨ re.finditer éæ­·æ‰€æœ‰å‰µæ„
    matches = re.finditer(pattern, final_message)

    for match in matches:
        # st.write(match)
        idea = match.group(1).strip()  # æ•è·ä»çŸ­æ¨ªçº¿åˆ° Originality ä¹‹é—´çš„å†…å®¹
        originality = int(match.group(2))
        elaboration = int(match.group(3))
        fluency = int(match.group(4))
        flexibility = int(match.group(5))

        # æª¢æŸ¥æ˜¯å¦ç¬¦åˆç¯©é¸æ¢ä»¶
        if originality >= originality_threshold and flexibility >= flexibility_threshold:
            # å°‡ç¬¦åˆæ¢ä»¶çš„å‰µæ„åŠ å…¥åˆ—è¡¨
            ideas.append({
                "idea": idea,
                "scores": {
                    "Originality": originality,
                    "Elaboration": elaboration,
                    "Fluency": fluency,
                    "Flexibility": flexibility
                }
            })

    return final_message, originality_score, elaboration_score, fluency_score, flexibility_score, ideas



# åˆå§‹åŒ–ä»£ç†çš„å›è¦†ç‹€æ…‹
def initialize_agent_states(round_num, agents):
    if f"round_{round_num}_agent_states" not in st.session_state:
        st.session_state[f"round_{round_num}_agent_states"] = {
            agent_name: False for agent_name in agents.keys()
        }

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

st.write("å·²ç¶“ç´¯ç©" + str(len(st.session_state.passed_ideas)) + "å€‹å‰µæ„")
if len(st.session_state.passed_ideas) >= 3:
    st.write(st.session_state.passed_ideas)
    st.write(st.session_state.full_scores)

# æ›´æ–°æŸä»£ç†çš„å›è¦†ç‹€æ…‹
def mark_agent_completed(round_num, agent_name):
    st.session_state[f"round_{round_num}_agent_states"][agent_name] = True


async def single_round_discussion(round_num, agents, user_proxy):
    initialize_agent_states(round_num, agents)
    
    # å¦‚æœè©²è¼ªå·²å®Œæˆï¼Œç›´æ¥è¿”å› True
    if st.session_state.get(f"round_{round_num}_completed", False):
        return True

    if round_num == 0:
        discussion_message = (
            f"é€™æ˜¯ç¬¬0è¼ªï¼Œ{question}"
        )
    else:
        # è¨­å®šè¨è«–å…§å®¹
        discussion_message = (
            f"é€™æ˜¯ç¬¬ {round_num} è¼ªè¨è«–ã€‚\n\n"
            f"ä¸Šä¸€è¼ªçš„è¨è«–å…§å®¹ï¼š\n\n{st.session_state.integrated_message}\n\n"
            f"é‡å°åŸæœ¬è¨è«–å…§å®¹é€²è¡Œå»¶ä¼¸ï¼ˆæç¤ºï¼šé¡Œç›®ç‚º {question}ï¼‰\n\n"
            f"ä»¥ä¸‹æ˜¯å›æ‡‰æ ¼å¼:\n\n"
            f"å‰›å‰›æåˆ°ï¼ˆå‰µæ„å…§å®¹ï¼‰ï¼Œæˆ‘è¦ºå¾—ä¾æ“šé¡Œç›®ï¼ˆæ€éº¼æ¨£ï¼‰ï¼Œé‚£å…¶å¯¦ä¹Ÿå¯ä»¥æœ‰ï¼ˆå»¶ä¼¸å‰µæ„ï¼‰"
        )

    
    this_round_input = st.session_state.user_inputs.get(round_num, "")

    for agent_name, agent in agents.items():
        if st.session_state[f"round_{round_num}_completed"]:
            break

        # st.write("é–‹é ­")
        # st.write(st.session_state.messages)
        if agent_name in ["Convergence Judge", "Assistant"]:
            continue


        if agent_name == "Normal Assistant 1":
            if st.session_state[f"round_{round_num}_agent_states"][agent_name]:
                continue
            with st.chat_message("assistant"):
                st.markdown(discussion_message)
            this_round_input = st.chat_input(f"è«‹è¼¸å…¥ç¬¬ {st.session_state.round_num} è¼ªçš„æƒ³æ³•ï¼š")

            # è™•ç†ç”¨æˆ¶è¼¸å…¥ï¼Œåªé‡å°ç•¶å‰è¼ªæ¬¡
            if this_round_input:
                st.session_state.messages.append({"role": "assistant", "content": discussion_message})

                # Display user message in chat message container
                with st.chat_message("user"):
                    st.markdown(this_round_input)
                # Add user message to chat history
                st.session_state.messages.append({"role": "user", "content": this_round_input})
                st.session_state[f"round_{round_num}_input_completed"] = True
                st.session_state.this_round_combined_responses[agent_name] = this_round_input
                st.session_state.user_inputs[round_num] = this_round_input
            else:
                # ç­‰å¾…è¼¸å…¥
                return False
        else:
            if st.session_state[f"round_{round_num}_agent_states"][agent_name]:
                continue
            response = await agent.a_initiate_chat(user_proxy, message=discussion_message, max_turns=1)
            response = response.chat_history[-1]["content"].strip()
            st.session_state.this_round_combined_responses[agent_name] = response
            # Display assistant response in chat message container
            with st.chat_message(agent_name):
                st.markdown(response)
            # Add assistant response to chat history
            st.session_state.messages.append({"role": agent_name, "content": response})
            mark_agent_completed(round_num, agent_name)

    # # æ›´æ–°æ•´åˆçš„æ­·å²è¨Šæ¯
    # st.session_state.integrated_message = "\n\n".join([
    #     f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages
    # ])


    if round_num == 0:
        # æª¢æŸ¥æ˜¯å¦å®Œæˆ
        st.session_state.integrated_message, originality_score, elaboration_score, fluency_score, flexibility_score, ideas = await check_novelty_and_feasibility(0, "", st.session_state.this_round_combined_responses, if_zero_round=True)
    else:
        st.session_state.integrated_message, originality_score, elaboration_score, fluency_score, flexibility_score, ideas = await check_novelty_and_feasibility(round_num, st.session_state.integrated_message, st.session_state.this_round_combined_responses)
    
    st.session_state.messages.append({"role": "Convergence Judge", "content": st.session_state.integrated_message})
    st.session_state.full_scores.append({"round": round_num, "originality": originality_score, "elaboration": elaboration_score, "fluency": fluency_score, "flexibility": flexibility_score})

    # å°‡é€šéç¯©é¸çš„å‰µæ„åŠ å…¥ passed_ideas åˆ—è¡¨
    for idea in ideas:
        st.session_state.passed_ideas.append(idea)
    
    if len(st.session_state.passed_ideas) >= 3:
        st.write(st.session_state.passed_ideas)
        st.write(st.session_state.full_scores)
        return True
    
    # st.write("çµæŸ")
    # st.write(st.session_state.messages)

    return True

# åˆå§‹åŒ– refresh_flag
if "refresh_flag" not in st.session_state:
    st.session_state.refresh_flag = False


# åœ¨è¼¸å…¥æ¡†æ¶ˆå¤±å¾Œé¡¯ç¤ºæç¤ºï¼Œç„¶å¾Œå†é¡¯ç¤ºä¸‹ä¸€è¼ªè¼¸å…¥æ¡†
if not st.session_state.show_input:
    st.write(f"å·²å®Œæˆç¬¬ {st.session_state.round_num - 1} è¼ªçš„è¼¸å…¥ï¼")
    st.session_state.show_input = True


if not st.session_state.discussion_started:
    if st.button("é–‹å§‹ LLM è¨è«–"):
        st.session_state.discussion_started = True
        st.session_state.round_num = 0
        st.session_state.integrated_message = f"é€™æ˜¯ç¬¬ 0 è¼ªè¨è«–ï¼Œ{question}ã€‚"

if st.session_state.discussion_started and st.session_state.round_num <= rounds:
    
    round_num = st.session_state.round_num
    # åŸ·è¡Œå–®è¼ªè¨è«–
    completed = asyncio.run(single_round_discussion(
        st.session_state.round_num, agents, user_proxy
    ))


    # if not st.session_state[f"round_{round_num}_input_completed"]:
    #     current_input = st.chat_input(f"è«‹è¼¸å…¥ç¬¬ {st.session_state.round_num} è¼ªçš„æƒ³æ³•ï¼š")
        
    #     if current_input:
    #         # ä¿å­˜è¾“å…¥å¹¶é‡ç½®çŠ¶æ€
    #         st.session_state.user_inputs[st.session_state.round_num] = current_input
    #         with st.chat_message("user"):
    #             st.markdown(current_input)

    #     completed = asyncio.run(single_round_discussion(
    #         st.session_state.round_num, agents, user_proxy
    #     ))

    if completed:
        # å¦‚æœè©²è¼ªå®Œæˆï¼Œé€²å…¥ä¸‹ä¸€è¼ª
        # st.write(f"å·²å®Œæˆç¬¬ {st.session_state.round_num} è¼ªï¼Œé€²å…¥ç¬¬ {st.session_state.round_num + 1} è¼ª")
        st.session_state.round_num += 1
        # time.sleep(1)
        st.rerun()
